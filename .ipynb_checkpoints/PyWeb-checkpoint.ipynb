{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center;font-size:70px;background-color:#0ad61b;color:white;font-style:italic;\">Python for web</p>\n",
    "\n",
    "![](http://www.blog.skytopper.com/wp-content/uploads/2015/06/Global-computer-network.jpg)\n",
    "\n",
    "This bootcamp is all about interacting with **web** using Python programming language!\n",
    "\n",
    "In this bootcamp, we will learn:\n",
    "\n",
    "- to work with web APIs\n",
    "- to download content from web\n",
    "- web scraping\n",
    "- web crawling\n",
    "\n",
    "using simple python scripts!\n",
    "\n",
    "![](https://i.amz.mshcdn.com/mqczOBQlR2uS7uALqB4fkKylDx0=/fit-in/1200x9600/https%3A%2F%2Fblueprint-api-production.s3.amazonaws.com%2Fuploads%2Fcard%2Fimage%2F193985%2Fnewhere.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with web APIs\n",
    "\n",
    "- **What is API?**<br>\n",
    "    API is a set of routines, protocols, and tools for building software applications. An API specifies how software components should interact. \n",
    "![](https://www.retriever.nl/wp-content/uploads/2016/11/api-321x250.png)\n",
    "-------------\n",
    "\n",
    "- **What is web API?**<br>\n",
    "    Web API is a framework for building HTTP services that can be consumed by a broad range of clients including browsers, mobiles, iphone and tablets.\n",
    "![](http://dselva.co.in/blog/wp-content/uploads/2017/09/Web-APIs.png)\n",
    "-----------------\n",
    "- **Some examples of public web APIs:**\n",
    "    - [Facebook Graph API](https://developers.facebook.com/docs/graph-api)\n",
    "    - [Twitter API](https://dev.twitter.com/rest/public)\n",
    "    - [Google API explorer](https://developers.google.com/apis-explorer/#p/)\n",
    "--------------\n",
    "\n",
    "- **What is REST?**<br>\n",
    "    REST is an architectural style followed by web services, in which, they allow requesting systems to access and manipulate their Web resources using a uniform and predefined set of **stateless operations**.\n",
    "    \n",
    "    >In computing, a stateless protocol is a communications protocol in which no information is retained by either sender or receiver. The sender transmits a packet to the receiver and does not expect an acknowledgment of receipt. There is nothing saved that has to be remembered by the next transaction. The server must be able to completely understand the client request without using any server context or server session state. \n",
    "    \n",
    "   Advantages of REST:\n",
    "   - As the transactions are stateless, we can direct them to any instance of the web service. (As no sessions are involved). Hence, the web service can scale to accommodate load changes.\n",
    "   - Binding to a service through an API is a matter of controlling how the URL is decoded.\n",
    "\n",
    "-----------------\n",
    "- **Types of HTTP requests**\n",
    "    - GET\n",
    "    - POST\n",
    "    - DELETE\n",
    "    - PUT\n",
    "    - PATCH, etc.\n",
    "    \n",
    "![](http://lotsofthing.com/wp-content/uploads/2017/11/rest-api-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP  for humans: [requests](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "<img src=\"http://docs.python-requests.org/en/master/_static/requests-sidebar.png\"  height=200 width=200>\n",
    "\n",
    "\n",
    "- Requests is one of the most downloaded Python packages of all time, pulling in over 7,000,000 downloads every month.All the cool kids are doing it\n",
    "\n",
    "- Recreational use of other HTTP libraries may result in dangerous side-effects, including: security vulnerabilities, verbose code, reinventing the wheel, constantly reading documentation, depression, headaches, or even death. Requests is the only Non-GMO HTTP library for Python, safe for human consumption.\n",
    "\n",
    "- Python HTTP: When in doubt, or when not in doubt, use Requests. Beautiful, simple, Pythonic.\n",
    "\n",
    "***Everybody loves it!***\n",
    "\n",
    "#### Installation\n",
    "\n",
    "```\n",
    "pip install requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET request\n",
    "\n",
    "### Example 1\n",
    "\n",
    "http://graph.facebook.com/4/picture?type=large\n",
    "\n",
    "![](http://graph.facebook.com/4/picture?type=large)\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTJ3ELNuC_coeH9tvLn62fsTMoe-vMVQrsfTrLUOIhsUI69i5QIyg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/gRvt4lV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "[Google maps geocoding API](https://developers.google.com/maps/documentation/geocoding/intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST request\n",
    "\n",
    "![](https://indianpythonista.files.wordpress.com/2016/12/iservice_post_get.png?w=809)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "[Pastebin API](https://pastebin.com/api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downloading files\n",
    "\n",
    "![](https://pics.onsizzle.com/downloading-98-downloading-99-downloading-failed-11367153.png)\n",
    "\n",
    "Downloading large files in chunks!\n",
    "\n",
    "http://www.greenteapress.com/thinkpython/thinkpython.pdf\n",
    "\n",
    "```python\n",
    "chunk_size = 256\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open(\"python.pdf\", \"wb\") as f:\n",
    "    for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "        f.write(chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Web scraping\n",
    "\n",
    "![](https://image.slidesharecdn.com/scrapingtotherescue-160713133749/95/getting-started-with-web-scraping-in-python-9-638.jpg?cb=1468417631)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    ">Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "\n",
    "### Installation\n",
    "\n",
    "```\n",
    "pip install bs4\n",
    "```\n",
    "\n",
    "**Bonus:**\n",
    "```\n",
    "pip install html5lib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.values.com/inspirational-quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.entropywebscraping.com/wp-content/uploads/2017/02/Screenshot-from-2017-02-01-10-23-00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Web crawling\n",
    "\n",
    "![](https://seopressor.com/wp-content/uploads/2016/04/how-crawler-works.png)\n",
    "\n",
    "> A web crawler (also known as a web spider or web robot) is a program or automated script which browses the World Wide Web in a methodical, automated manner.\n",
    "\n",
    "#### Why web crawling?\n",
    "- web indexing\n",
    "- web scraping\n",
    "- sitemap generator\n",
    "\n",
    "#### Did you know?\n",
    "> ***Googlebot*** is Google's web crawling bot (sometimes also called a \"spider\"). Crawling is the process by which Googlebot discovers new and updated pages to be added to the Google index.\n",
    "\n",
    "> It uses a huge set of computers to fetch (or \"crawl\") billions of pages on the web. Googlebot uses an algorithmic process: computer programs determine which sites to crawl, how often, and how many pages to fetch from each site.\n",
    "\n",
    "> Googlebot's crawl process begins with a list of webpage URLs, generated from previous crawl processes and augmented with Sitemap data provided by webmasters. As Googlebot visits each of these websites it detects links (SRC and HREF) on each page and adds them to its list of pages to crawl. New sites, changes to existing sites, and dead links are noted and used to update the Google index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def link_extractor(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "    links = soup.findAll('a', attrs={'href': re.compile(\"^http(s)?\")})\n",
    "    urls = [link['href'] for link in links]\n",
    "    return urls\n",
    "    \n",
    "def crawl(source_url, limit=1000000): \n",
    "    to_visit = [source_url]\n",
    "    visited = [] \n",
    "    \n",
    "    while len(to_visit) != 0 and len(visited) < limit:\n",
    "        url = to_visit.pop(0)\n",
    "        visited.append(url)\n",
    "        \n",
    "        print(\"Visiting \"+url)\n",
    "        new_links = link_extractor(url)\n",
    "        for link in new_links:\n",
    "            if link not in visited and link not in to_visit:\n",
    "                to_visit.append(link)\n",
    "                \n",
    "    return visited + to_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links = crawl(\"https://indianpythonista.wordpress.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some tweaks...\n",
    "- multithreading\n",
    "- robots.txt\n",
    "- priority score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resourses:\n",
    "\n",
    "- Python packages:\n",
    "\n",
    "    - [requests](http://docs.python-requests.org/en/master/)\n",
    "\n",
    "    - [bs4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "    \n",
    "    - [html5lib](https://html5lib.readthedocs.io/en/latest/)\n",
    "    \n",
    "    - [Scrapy | A Fast and Powerful Scraping and Web Crawling Framework](https://scrapy.org)\n",
    "\n",
    "\n",
    "- Articles:\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/get-and-post-requests-using-python/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/10/18/requests-http-for-pythonistas/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/downloading-files-from-web-using-python/\n",
    "\n",
    "    - https://indianpythonista.wordpress.com/2016/12/10/implementing-web-scraping-in-python-with-beautiful-soup/\n",
    "\n",
    "\n",
    "- Videos:\n",
    "\n",
    "    - File downloader: https://www.youtube.com/watch?v=Xhw2l-hzoKk\n",
    "    \n",
    "    - Web scraping: https://www.youtube.com/watch?v=lIkd_jt28i0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
